'''
This project is created from synthetic data for learning purposes.
Reference: Ayodele Oluleye(2023).
'''

'''
Objective:
This report details the process of preparing textual review data for a bike sales dataset. 
The primary objective is to transform raw, unstructured text into a clean and structured format suitable for downstream analytical tasks such as sentiment analysis or topic modeling. 
The process involves a series of text preprocessing techniques applied using the Python programming language and several key libraries.
'''

'''
Project Environment
The data processing was conducted within a Python environment, leveraging the capabilities of several specialized libraries. 
The pandas library was instrumental in handling the dataset, providing data structures and functions for efficient manipulation and analysis of tabular data, including reading the CSV file containing the reviews [Insight 2]. 
For the core text processing tasks, the Natural Language Toolkit (nltk) library was employed. 
This library offers a wide range of tools for tokenization, stop word removal, and other natural language processing techniques. 
Specifically, functionalities for tokenizing text into individual words and accessing lists of common English stop words were utilized. 
Additionally, the contractions library was used to expand common English contractions present in the text. 
The download of various NLTK resources, including punkt, stopwords, wordnet, averaged_perceptron_tagger, vader_lexicon, and omw-1.4, suggests a comprehensive approach to natural language processing, potentially encompassing tasks beyond the immediate scope of data cleaning, such as part-of-speech tagging and sentiment analysis

'''

'''
Project Scope
The focus of this project is specifically on the 'Review' column within the "bike_sales2.csv" dataset. 
The goal is to apply a series of transformations to this textual data to prepare it for further analysis. 
The transformations performed include expanding contractions, breaking down the text into individual words (tokenization), converting all text to lowercase, and removing punctuation marks. 
These steps are crucial for standardizing the text data and removing noise, thereby making it more amenable to computational analysis.
The project's scope is limited to these preprocessing steps and does not extend to in-depth exploratory data analysis or the development of predictive models.
'''

# Import relevant libraries
import pandas as pd
import string
import nltk

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import contractions
import nltk
nltk.download('punkt_tab')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger')
nltk.download('vader_lexicon')
nltk.download('omw-1.4')
nltk.download('punkt')


# Load dataset
reviews_data = pd.read_csv("bike_sales2.csv")

#Inspect first 5 rows and data types of the dataset
print(reviews_data.head())

print(reviews_data.shape)

#Expand Contractions

# This replaces NaN values in the 'Review' column with an empty string.
reviews_data['Review'] = reviews_data['Review'].fillna('')


reviews_data['no_contractions'] = reviews_data['Review'].apply(lambda x: [contractions.fix(word) for word in x.split()])
print(reviews_data.head(7))

reviews_data['reviews_no_contractions'] = [' '.join(l) for l in reviews_data['no_contractions']]
print(reviews_data.head(7))

#Tokenize data
reviews_data['reviews_tokenized'] = reviews_data['reviews_no_contractions'].apply(word_tokenize)
print(reviews_data.head(7))

#Convert data to lower case
reviews_data['reviews_lower'] = reviews_data['reviews_tokenized'].apply(lambda x: [word.lower() for word in x])
print(reviews_data.head())

#Remove punctuations

punctuations = string.punctuation
reviews_data['reviews_no_punctuation'] = reviews_data['reviews_lower'].apply(lambda x: [word for word in x if word not in punctuations])
print(reviews_data.head())

#Convert output back to string
reviews_data['reviews_cleaned'] = [' '.join(l) for l in reviews_data['reviews_no_punctuation']]
print(reviews_data.head())

#Export Cleaned Text data
reviews_data[['Review','Liked','reviews_cleaned']].to_csv('cleaned_bike_sales2.csv',index = False)

